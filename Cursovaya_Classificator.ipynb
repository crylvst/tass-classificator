{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b0cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e04f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции для очистки текста\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "def remove_HTML(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    num = re.compile(r'\\d+')\n",
    "    return num.sub(r'', text)\n",
    "\n",
    "def remove_spaces(text):\n",
    "    spaces = re.compile(r'  ')\n",
    "    return spaces.sub(r' ', text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    punct = re.compile(r'[^\\w\\s]')\n",
    "    return punct.sub(r'', text) \n",
    "\n",
    "# def remove_TASS(text):\n",
    "#     tass = re.compile(r'ТАСС')\n",
    "#    return tass.sub(r'', text)\n",
    "\n",
    "def remove_months(text):\n",
    "    months = ['январь', 'февраль', 'март', 'апрель', 'май', 'июнь',\n",
    "              'июль', 'август', 'сентябрь', 'октябрь', 'ноябрь', 'декабрь']\n",
    "    for elm in months:\n",
    "        text = text.replace(elm, '')\n",
    "    return text\n",
    "\n",
    "def remove_wordsNumbers(text):\n",
    "    numbers = ['год', 'млн', 'тыс', 'км', 'млрд', 'тонна', 'возраст', 'гг', 'назад']\n",
    "    for i in numbers:\n",
    "        text = text.replace(i, '')\n",
    "    return text\n",
    "    \n",
    "def remove_useless(text):\n",
    "    useless = ['это', 'который', 'ТАСС', 'twitter', 'понедельник', 'вторник', 'среда',\n",
    "               'четверг', 'пятница', 'суббота', 'воскресенье']\n",
    "    for _ in useless:\n",
    "        text = text.replace(_, '')\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = remove_TASS(text)\n",
    "    text = remove_URL(text)\n",
    "    text = remove_HTML(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punct(text)\n",
    "#    text = remove_spaces(text)\n",
    "    return text\n",
    "\n",
    "# функция лемматизации\n",
    "mystem = Mystem()\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords \\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47b147e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/hp/TASS_news/100/ekonomika_100.csv\",encoding='utf8',index_col=0)\n",
    "df2 = pd.read_csv(\"C:/Users/hp/TASS_news/100/kultura_100.csv\",encoding='utf8',index_col=0)\n",
    "df3 = pd.read_csv(\"C:/Users/hp/TASS_news/100/nauka_100.csv\",encoding='utf8',index_col=0)\n",
    "df4 = pd.read_csv(\"C:/Users/hp/TASS_news/100/politika_100.csv\",encoding='utf8',index_col=0)\n",
    "df5 = pd.read_csv('C:/Users/hp/TASS_news/100/sport_100.csv',encoding='utf8',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "224ba439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n"
     ]
    }
   ],
   "source": [
    "df_tass = pd.concat([df1,df2,df3,df4,df5], axis = 0,ignore_index=True)\n",
    "#реиндексация\n",
    "df_tass = df_tass.reindex(index=[i for i in range(df_tass.shape[0])])\n",
    "df_tass.to_csv('textsTASS.csv')\n",
    "print(df_tass.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bab9c0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Head</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Text</th>\n",
       "      <th>Rubric</th>\n",
       "      <th>Classi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>УНИКС победил \"Андорру\" в первом туре топ-16 б...</td>\n",
       "      <td>Встреча завершилась со счетом 73:66</td>\n",
       "      <td>ТАСС, 13 января. Российский баскетбольный клуб...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>501</td>\n",
       "      <td>\"Зенит\" уступил \"Баварии\" и прервал серию из т...</td>\n",
       "      <td>Встреча закончилась со счетом 80:82</td>\n",
       "      <td>ТАСС, 13 января. Российский \"Зенит\" на выезде ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>502</td>\n",
       "      <td>Кущенко: Единая лига ВТБ вынуждена оптимизиров...</td>\n",
       "      <td>Глава лиги отметил, что в первый день было про...</td>\n",
       "      <td>МОСКВА, 13 января. /Корр. ТАСС Андрей Карташов...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>Шибалов: организаторы на старте этапа \"Дакара\"...</td>\n",
       "      <td>Все экипажи стартовали друг за другом с тридца...</td>\n",
       "      <td>МОСКВА, 13 января. /ТАСС/. Организаторы ралли-...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>Карякин: нас ждут в штабе \"Дакара\" из-за видео...</td>\n",
       "      <td>На девятом этапе ралли-марафона багги российск...</td>\n",
       "      <td>МОСКВА, 13 января. /ТАСС/. Организаторы ралли-...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               Head  \\\n",
       "500         500  УНИКС победил \"Андорру\" в первом туре топ-16 б...   \n",
       "501         501  \"Зенит\" уступил \"Баварии\" и прервал серию из т...   \n",
       "502         502  Кущенко: Единая лига ВТБ вынуждена оптимизиров...   \n",
       "503         503  Шибалов: организаторы на старте этапа \"Дакара\"...   \n",
       "504         504  Карякин: нас ждут в штабе \"Дакара\" из-за видео...   \n",
       "\n",
       "                                                  Lead  \\\n",
       "500                Встреча завершилась со счетом 73:66   \n",
       "501                Встреча закончилась со счетом 80:82   \n",
       "502  Глава лиги отметил, что в первый день было про...   \n",
       "503  Все экипажи стартовали друг за другом с тридца...   \n",
       "504  На девятом этапе ралли-марафона багги российск...   \n",
       "\n",
       "                                                  Text Rubric  Classi  \n",
       "500  ТАСС, 13 января. Российский баскетбольный клуб...  sport       2  \n",
       "501  ТАСС, 13 января. Российский \"Зенит\" на выезде ...  sport       2  \n",
       "502  МОСКВА, 13 января. /Корр. ТАСС Андрей Карташов...  sport       2  \n",
       "503  МОСКВА, 13 января. /ТАСС/. Организаторы ралли-...  sport       2  \n",
       "504  МОСКВА, 13 января. /ТАСС/. Организаторы ралли-...  sport       2  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tass.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ce4b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tass = pd.read_csv(\"C:/Users/hp/textsTASS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "340fd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tass['Classi'] = df_tass['Rubric'].map({'nauka': 0, 'kultura': 1, 'sport': 2, 'politika': 3, 'ekonomika': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8c17969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tass[\"Clean_text\"] = df_tass[\"Text\"].apply(clean_text)\n",
    "df_tass[\"Clean_text\"] = df_tass[\"Clean_text\"].apply(preprocess_text)\n",
    "df_tass[\"Clean_text\"] = df_tass[\"Clean_text\"].apply(remove_months)\n",
    "df_tass[\"Clean_text\"] = df_tass[\"Clean_text\"].apply(remove_wordsNumbers)\n",
    "df_tass[\"Clean_text\"] = df_tass[\"Clean_text\"].apply(remove_useless)\n",
    "df_tass[\"Clean_text\"] = df_tass[\"Clean_text\"].apply(remove_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "638edc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'москва обвинение журналист владимир соловьев сторона глава мид латвия эдгарс ринкевичса якобы иметь место эфир героизация нацизм являться чушь заявлять брифинг официальный представитель мид рф мария захаров комментировать запрет соловьев въезд латвия напоминать министр иностранный дело латвия обвинять соловьев прославление нацизм отмечать повидеть ринкевичса возможность посмотреть исходный материал комментировать изза блокировка страна телеканал вгтрк придумывать чушь иначе глава мид латвия знать настолько ярый антифашист владимир соловьев посвящать тема борьба коричневый чума значительный часть свой эфирный время находить просто сложно указывать захаров дипломат подчеркивать данный ситуация цинизм латвийский власть превосходить весь допустимый граница поведение рига требовать квалификация скоро правовой указывать взяться борьба нацизм пора переставать попустительствовать прославлять гражданин латвия добавлять дипломат официальный представитель мид рф также напоминать латвия вместе ряд страна поддерживать резолюция совбез оон борьба героизация нацизм ранее соловьев включать черный список лицо запрещать въезд территория латвия'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tass.loc[307]['Clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3341d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизация\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "train_tfidf_vec = vec.fit(df_tass['Clean_text'])  \n",
    "# test_tfidf_vec = vec.fit(df_test_clean['text'])\n",
    "\n",
    "vec_train = train_tfidf_vec.transform(df_tass['Clean_text'])\n",
    "# vec_test = test_tfidf_vec.transform(df_test_clean['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97bfd2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train embedded vector is (505, 14769)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the train embedded vector is {}\".format(vec_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "651b2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vec_train\n",
    "y = df_tass['Classi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e529466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d586473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# наивный Байес\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "mnb = MultinomialNB(alpha=1).fit(X_train, y_train)\n",
    "predicted_mnb = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9767665b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 0, 3, 0, 2, 1, 1, 0, 0, 3,\n",
       "       2, 1, 4, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 3, 2, 0, 1, 3, 4, 2, 0,\n",
       "       4, 4, 2, 3, 2, 1, 3, 1, 0, 1, 1, 4, 3, 1, 3, 0, 4, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 3, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "abfac40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# деревья решений\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=107, min_samples_split=5, min_samples_leaf=1, max_depth=None)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "predicted_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73436dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 0, 3, 0, 2, 1, 1, 0, 0, 3,\n",
       "       2, 1, 3, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 3, 2, 0, 1, 3, 4, 2, 0,\n",
       "       4, 4, 2, 3, 2, 1, 3, 1, 0, 1, 1, 4, 4, 1, 3, 0, 4, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ae9af330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 1, 0, 0, 3,\n",
       "       2, 1, 4, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 4, 2, 0, 1, 3, 4, 2, 0,\n",
       "       4, 4, 2, 3, 2, 1, 3, 1, 0, 1, 1, 4, 4, 1, 3, 0, 3, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 3, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af253e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метод К-ближайших соседей\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "predicted_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71af4b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 3, 2, 4, 3, 3, 1, 1, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 4, 2,\n",
       "       2, 1, 2, 3, 4, 3, 2, 2, 3, 2, 1, 2, 0, 3, 2, 2, 2, 1, 2, 2, 2, 4,\n",
       "       2, 4, 2, 3, 2, 1, 2, 1, 0, 2, 2, 4, 2, 1, 3, 0, 4, 0, 2, 2, 2, 1,\n",
       "       4, 2, 1, 4, 1, 4, 3, 3, 1, 2, 2, 4, 2, 2, 2, 4, 2, 2, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 2, 2, 1, 2, 2, 2, 3, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "514312e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 3, 2, 4, 2, 3, 1, 1, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 4, 2,\n",
       "       2, 2, 2, 3, 4, 3, 2, 2, 3, 2, 1, 2, 0, 3, 2, 2, 2, 2, 2, 2, 2, 4,\n",
       "       2, 4, 2, 3, 2, 1, 2, 1, 0, 2, 2, 4, 2, 1, 3, 0, 4, 0, 2, 2, 2, 1,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 2, 2, 4, 2, 2, 2, 4, 2, 2, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de0a77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метод опорных векторов\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=5)\n",
    "svc.fit(X_train, y_train)\n",
    "predicted_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55c92c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 0, 3, 0, 2, 1, 1, 4, 0, 3,\n",
       "       2, 1, 4, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 3, 2, 1, 1, 3, 3, 2, 0,\n",
       "       4, 4, 2, 3, 2, 1, 3, 1, 0, 1, 1, 4, 3, 1, 3, 0, 4, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 0,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28d8da42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 1, 4, 0, 3,\n",
       "       2, 1, 4, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 3, 2, 0, 1, 3, 3, 2, 0,\n",
       "       4, 4, 2, 3, 2, 1, 3, 1, 0, 1, 1, 4, 3, 1, 3, 0, 4, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 0,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 3, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c6ce1a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier (learning_rate=0.02, n_estimators=600, subsample=0.6, min_child_weight=1, max_depth=40, gamma=1, colsample_bytree=1.0)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "predicted_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b59d1458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 0, 1, 0, 3, 1, 1, 0, 0, 3,\n",
       "       2, 1, 4, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 4, 2, 0, 1, 3, 3, 2, 0,\n",
       "       4, 4, 2, 3, 2, 1, 3, 1, 0, 3, 1, 4, 4, 1, 3, 0, 4, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 3, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13100de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 3, 0, 1, 0, 3, 1, 1, 0, 0, 3,\n",
       "       2, 1, 3, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 4, 2, 0, 1, 3, 4, 2, 0,\n",
       "       4, 3, 2, 3, 2, 1, 2, 1, 0, 1, 1, 4, 4, 1, 3, 0, 3, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 3, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "11f3c65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:38:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:38:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# стекинг моделей\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    (\"mnb\", mnb),\n",
    "    (\"rfc\", rfc),\n",
    "    (\"knn\", knn),\n",
    "    (\"svc\", svc),\n",
    "    (\"xgb\", xgb_model)\n",
    "]\n",
    "\n",
    "sc = StackingClassifier(estimators=estimators,cv=5)\n",
    "\n",
    "sc.fit(X_train, y_train)\n",
    "predicted_sc = sc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c0a7e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 0, 3, 0, 2, 1, 1, 0, 0, 3,\n",
       "       2, 1, 4, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 3, 2, 0, 1, 3, 4, 2, 0,\n",
       "       4, 4, 2, 3, 2, 1, 3, 1, 0, 1, 1, 4, 3, 1, 3, 0, 4, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6cd94292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 1, 0, 0, 3,\n",
       "       2, 1, 4, 3, 4, 3, 4, 0, 3, 3, 1, 2, 0, 3, 3, 2, 0, 1, 3, 4, 2, 0,\n",
       "       4, 4, 2, 3, 2, 1, 3, 1, 0, 1, 1, 4, 3, 1, 3, 0, 4, 0, 3, 2, 3, 0,\n",
       "       4, 2, 2, 4, 1, 4, 3, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 3, 3, 3, 2, 1,\n",
       "       3, 4, 3, 2, 3, 2, 1, 2, 4, 2, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fff6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
